{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Aggregate game information from multiple sources\n",
    "\n",
    "In this script, we bring together a bunch of information about games that are available on Steam and save them in a database. The two main sources of information are an unofficial API called 'steampowered', as well web scraping the steam store. \n",
    "\n",
    "We are interested in the following information: \n",
    "- Each games web store app ID\n",
    "- A detailed description of each game\n",
    "- The game developers (ed, 'Valve')\n",
    "- The initial and final price of each game\n",
    "- The game title\n",
    "- Game genre (eg, 'Action'))\n",
    "- A metacritic score for each game\n",
    "- How many recommendations has the game received\n",
    "- The games release date\n",
    "- Tags for each game, of which each game typically has around 10 (eg, 'FPS', 'Simulation', 'Racing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "from forex_python.converter import CurrencyRates\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "\n",
    "currentRates = CurrencyRates() # Get current curreny exchange rates\n",
    "\n",
    "# Load in previously sorted game counts. \n",
    "with open('gameCounts.pickle', 'rb') as inputfile:\n",
    "    gameCounts = pickle.load(inputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect game information\n",
    "\n",
    "In the function below, we first query gameinformation from the 'steampowered' API, and then use BeautifulSoup to scrape the Steam web store for tags. Al of this information is then stored in a pandas dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define funciton to query game information and return feature dict\n",
    "def grabGameInfo(gameID):\n",
    "    # Query game info\n",
    "    currentRequest = requests.get(\"http://store.steampowered.com/api/appdetails?appids={}\".format(gameID))\n",
    "    try:\n",
    "        jsonIndex   = re.search(r'\\d+', currentRequest.text).group()\n",
    "        json2pyData = json.loads(currentRequest.content)\n",
    "        try:\n",
    "            \n",
    "            gameData = json2pyData[jsonIndex]['data'] # all info in json nested format\n",
    "            gameKeys = gameData.keys()\n",
    "            tempDict = dict()\n",
    "            tempDict['gameName']            = gameData['name']\n",
    "            tempDict['type']                = gameData['type']\n",
    "            tempDict['detailedDescription'] = gameData['detailed_description']\n",
    "            tempDict['developers']          = gameData['developers'][0]\n",
    "            tempDict['genre']               = gameData['genres'][0]['description']\n",
    "            tempDict['is_free']             = gameData['is_free']\n",
    "\n",
    "            # Control for the case that certain fields are not present\n",
    "            if 'metacritic' in gameKeys:\n",
    "                tempDict['metacriticScore'] = gameData['metacritic']['score']\n",
    "            else: \n",
    "                tempDict['metacriticScore'] = 'Empty'\n",
    "            if 'recommendations' in gameKeys:\n",
    "                tempDict['recommendations'] = gameData['recommendations']['total']\n",
    "            else:\n",
    "                tempDict['recommendations'] = 'Empty' \n",
    "\n",
    "            # The code below loads in the date of the game release and converts it into an integer with format %YYYY%MM%DD\n",
    "            #release_date = datetime.datetime.strptime(gameData['release_date']['date'], '%b %d, %Y')\n",
    "            try:\n",
    "                release_date = dateutil.parser.parse(gameData['release_date']['date'])\n",
    "                yearStr  = str(release_date.year)\n",
    "                monthStr = str(release_date.month)\n",
    "                dayStr   = str(release_date.day)\n",
    "                if len(monthStr) == 1:\n",
    "                    monthStr = \"0\" + monthStr\n",
    "                if len(dayStr) == 1:\n",
    "                    dayStr = \"0\" + dayStr\n",
    "                tempDict['releaseDate'] = int(yearStr + monthStr + dayStr)  \n",
    "            except:\n",
    "                tempDict['releaseDate'] = 'Empty'\n",
    "\n",
    "            # Get the price of the game and convert it to US dollars if it is in another currency\n",
    "            if 'price_overview' in gameKeys:\n",
    "                currency = gameData['price_overview']['currency']\n",
    "                if currency != 'USD':\n",
    "                    init_price  = (gameData['price_overview']['initial'] * currentRates.get_rates('USD')[currency])/100\n",
    "                    final_price = (gameData['price_overview']['final'] * currentRates.get_rates('USD')[currency])/100\n",
    "                else:\n",
    "                    init_price  = (gameData['price_overview']['initial'])/100\n",
    "                    final_price = (gameData['price_overview']['final'])/100\n",
    "                tempDict['init_price']  = init_price\n",
    "                tempDict['final_price'] = final_price\n",
    "            else: # If there is no price information\n",
    "                tempDict['init_price'] = 'Empty'\n",
    "                tempDict['final_price'] = 'Empty'\n",
    "\n",
    "            # Now let's scrape the steam store website to obtain the specific tags for each game    \n",
    "            url  = \"http://store.steampowered.com/app/{}/\".format(str(gameID)) # URL for game\n",
    "            page = urlopen(url) \n",
    "            soup = BeautifulSoup(page,'lxml') # scrape page\n",
    "            links = soup.find_all(\"a\") # The tag information is contained in some of the links on the page    \n",
    "\n",
    "            tags = [] # initialize tags list\n",
    "            for link in links:\n",
    "                            # We try this because some links don't have have a field 'class' \n",
    "                try:\n",
    "                    if link.get(\"class\")[0] == \"app_tag\":\n",
    "                        linkContents = link.contents[0]\n",
    "                        tags.append(re.sub('\\s+', '', linkContents))\n",
    "                except:\n",
    "                    pass    \n",
    "            tempDict['tags'] = tags\n",
    "            \n",
    "        except:\n",
    "            return('Empty')\n",
    "\n",
    "\n",
    "        print(tempDict['gameName'] ,end = \"\\r\")\n",
    "    except:\n",
    "        return('Empty')\n",
    "    \n",
    "    return(tempDict)\n",
    "\n",
    "numGames = 20000 # number of games to query\n",
    "gameDict = {str(gameID): grabGameInfo(gameID) for gameID, count in gameCounts.most_common(numGames)}\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save game information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's save the dict as a json file \n",
    "jsonFile = json.dumps(gameDict)\n",
    "f = open(\"gameDict_20k.json\",\"w\")\n",
    "f.write(jsonFile)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load game dict back in if we need to\n",
    "with open('gameDict_20k.json') as json_data:\n",
    "    gameDict = json.load(json_data)\n",
    "# load game data into a dataframe\n",
    "gameDataframe = pd.DataFrame(gameDict)\n",
    "gameDataframe = gameDataframe.T # transpose to get "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to PostgreSQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SQL database info\n",
    "db_name  = 'UserInfo'\n",
    "username = 'username'\n",
    "host     = 'localhost'\n",
    "pwd      = 'password'\n",
    "port     = '5432'\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(username, pwd, host, port, db_name))\n",
    "print(engine.url)\n",
    "\n",
    "# connect to the database:\n",
    "con = None\n",
    "con = psycopg2.connect(database = db_name, user = username, password = pwd, host = host)\n",
    "cur = con.cursor() # get a cursor to our current connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For writing the game data into SQL we want to replace 'Empty' entries with NaN's\n",
    "gameDataframe = gameDataframe.replace('Empty',np.nan)\n",
    "# Then we write all the game data into a .csv file\n",
    "gameDataframe.to_csv(\"/home/iain/Documents/InsghtProject/allGames.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy game data into the database\n",
    "\n",
    "Similar to the user information, we would like to save game information into a relational database to make it easier to query and interact with. In the cell below we first initialize a data table in the database, and then copy our game data into the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a query to initialize the allGames table in postgres.\n",
    "# Then we copy our data from the csv file into the table we just created. \n",
    "# These changes have to be committed, otherwise thy will not be permanent\n",
    "# Finally, I query some data from the tabe, since the read_sql function expects an output.\n",
    "create_table_sql = \"\"\"\n",
    "CREATE TABLE allgames\n",
    "(\n",
    "  gameID numeric NULL,\n",
    "  detaileDescription text NULL,\n",
    "  developers text NULL,\n",
    "  final_price numeric NULL,\n",
    "  gameName text NULL,\n",
    "  genre text NULL,\n",
    "  init_price numeric NULL,\n",
    "  is_free text NULL,\n",
    "  metacriticScore numeric NULL,\n",
    "  recommendations numeric NULL,\n",
    "  releaseDate numeric NULL,\n",
    "  tags text NULL,\n",
    "  type text NULL\n",
    ");\n",
    "\n",
    "COPY allgames FROM '/home/iain/Documents/InsghtProject/allGames.csv' WITH DELIMITER ',' HEADER CSV;\n",
    "\n",
    "COMMIT;\n",
    "\n",
    "SELECT * FROM allgames WHERE final_price = 9.99;\n",
    "\"\"\"\n",
    "# Run the above command using postgres\n",
    "gameInfo = pd.read_sql_query(create_table_sql,con)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
