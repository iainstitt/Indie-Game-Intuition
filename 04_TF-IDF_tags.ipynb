{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare TF-IDF dictionary and corpus for game tags\n",
    "\n",
    "To engineer a feature that quantifies the similarity of a games tags and the tags of the games a user currently owns, we have to generate a dictionary and corpus of words that we can feed to the tf-idf model. What the model does is vectirize word representations based on term frequency in each document (or tags in this case). We can then use these vectorized representations to compute how similar two different document vectors are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import json\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "from gensim import corpora, models, similarities\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "json_data=open(\"/home/iain/gameDict.json\").read()\n",
    "jsonFile = json.loads(json_data)\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://iain:4ll3nd3@localhost:5432/UserInfo\n"
     ]
    }
   ],
   "source": [
    "# Define SQL database info\n",
    "db_name  = 'UserInfo'\n",
    "username = 'username'\n",
    "host     = 'localhost'\n",
    "pwd      = 'pasword'\n",
    "port     = '5432'\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(username, pwd, host, port, db_name))\n",
    "print(engine.url)\n",
    "\n",
    "# connect to database:\n",
    "con = None\n",
    "con = psycopg2.connect(database = db_name, user = username, password = pwd, host = host)\n",
    "cur = con.cursor() # get a cursor to our current connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query game data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a query to grab all game information\n",
    "create_table_sql = \"\"\"\n",
    "SELECT * FROM allGames WHERE tags IS NOT NULL;\n",
    "\"\"\"\n",
    "games = pd.read_sql_query(create_table_sql,con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize game tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tokenize each game \n",
    "documents   = [] # initialise documents\n",
    "allGameTags = games['tags'].values.tolist() # Get a list of all game lists (this is a string)\n",
    "for tags in allGameTags:\n",
    "    currentTags = ast.literal_eval(tags) # Evaluate to get in list form\n",
    "    documents.append(' '.join(currentTags)) # Join all together with spaces\n",
    "# Loop through each game and tokenize game tags\n",
    "texts = [[w.lower() for w in word_tokenize(document)] for document in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dictionary from tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-17 13:29:35,330 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2017-09-17 13:29:35,521 : INFO : built Dictionary(335 unique tokens: ['action', 'fps', 'multiplayer', 'shooter', 'classic']...) from 4722 documents (total 34135 corpus positions)\n",
      "2017-09-17 13:29:35,524 : INFO : saving Dictionary object under /home/iain/Documents/InsghtProject/gameTagDict.dict, separately None\n",
      "2017-09-17 13:29:35,526 : INFO : saved /home/iain/Documents/InsghtProject/gameTagDict.dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(335 unique tokens: ['action', 'fps', 'multiplayer', 'shooter', 'classic']...)\n"
     ]
    }
   ],
   "source": [
    "# Generate a dictionary of tags from our preprocessed list of game tags\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.save('/home/gameTagDict.dict')  # store the dictionary, for future reference\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get corpus from tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-17 13:29:39,104 : INFO : storing corpus in Matrix Market format to /home/iain/Documents/InsghtProject/gameTagCorpus.mm\n",
      "2017-09-17 13:29:39,111 : INFO : saving sparse matrix to /home/iain/Documents/InsghtProject/gameTagCorpus.mm\n",
      "2017-09-17 13:29:39,114 : INFO : PROGRESS: saving document #0\n",
      "2017-09-17 13:29:39,162 : INFO : PROGRESS: saving document #1000\n",
      "2017-09-17 13:29:39,198 : INFO : PROGRESS: saving document #2000\n",
      "2017-09-17 13:29:39,237 : INFO : PROGRESS: saving document #3000\n",
      "2017-09-17 13:29:39,258 : INFO : PROGRESS: saving document #4000\n",
      "2017-09-17 13:29:39,272 : INFO : saved 4722x335 matrix, density=2.156% (34113/1581870)\n",
      "2017-09-17 13:29:39,273 : INFO : saving MmCorpus index to /home/iain/Documents/InsghtProject/gameTagCorpus.mm.index\n"
     ]
    }
   ],
   "source": [
    "# Generate a corpus matrix from the tags \n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "# Save the corpus to disk\n",
    "corpora.MmCorpus.serialize('/home/gameTagCorpus.mm', corpus) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize tf-idf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-17 11:21:20,775 : INFO : collecting document frequencies\n",
      "2017-09-17 11:21:20,777 : INFO : PROGRESS: processing document #0\n",
      "2017-09-17 11:21:20,794 : INFO : calculating IDF weights for 4722 documents and 334 features (34113 matrix non-zeros)\n"
     ]
    }
   ],
   "source": [
    "# Initialise a term-frequency inverse document frequency model based on the corpus\n",
    "tfidf = models.TfidfModel(corpus) \n",
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize similarity index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-17 11:21:25,058 : INFO : starting similarity index under /home/iain/Documents/InsghtProject/\n"
     ]
    }
   ],
   "source": [
    "# Initialise a similarity index using the stored index, corpus, and dictionary\n",
    "sims = similarities.Similarity('/home/',tfidf[corpus],num_features=len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example use case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['casual', 'space', 'indie', 'fps', 'early', 'access']\n",
      "[(1, 1), (29, 1), (30, 1), (40, 1)]\n",
      "[(1, 0.6525071878230797), (29, 0.24677895019256244), (30, 0.7100944028664118), (40, 0.09539632382260485)]\n",
      "[ 0.09971548  0.1439738   0.          0.36022088  0.          0.13437054\n",
      "  0.13437054  0.          0.          0.00299126]\n"
     ]
    }
   ],
   "source": [
    "# Now let's test the model on a hypothetical game with certain tags\n",
    "# Tokenize\n",
    "query_doc = [w.lower() for w in word_tokenize(\"casual space indie FPS early access \")]\n",
    "print(query_doc)\n",
    "# Compare to dictionary we computed on all other games\n",
    "query_doc_bow = dictionary.doc2bow(query_doc)\n",
    "print(query_doc_bow)\n",
    "# Vectorize word representation\n",
    "query_doc_tf_idf = tfidf[query_doc_bow]\n",
    "print(query_doc_tf_idf)\n",
    "query_similarity = sims[query_doc_tf_idf]\n",
    "print(query_similarity[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
